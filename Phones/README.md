# LRS3 Phoneme Conversion Guide

This guide explains how to convert word-level transcripts from the LRS3 preprocessing pipeline into phoneme-level transcripts for training phoneme-based lip reading models.

## Overview

Phoneme-level training can improve lip reading accuracy by providing a more fine-grained representation of speech units. This conversion process transforms word transcripts (`.wrd` files) into phoneme transcripts (`.phn` files) using Grapheme-to-Phoneme (G2P) conversion.

## Prerequisites

### Required Python Packages
```bash
pip install g2p-en tqdm
```

### Input Requirements
You need the completed LRS3 preprocessing pipeline output containing:
- `train.wrd`, `valid.wrd`, `test.wrd` files from step 3
- These are generated by running `step3_metadata_prep.py`

## Usage

### Basic Conversion
Convert all word transcripts to phonemes with default settings:

```bash
python create_phoneme_metadata.py --metadata-dir /path/to/lrs3/metadata
```

### Advanced Options
```bash
# Process only specific splits
python create_phoneme_metadata.py \
  --metadata-dir /path/to/lrs3/metadata \
  --splits train,test

# Keep stress markers (0,1,2) in phonemes  
python create_phoneme_metadata.py \
  --metadata-dir /path/to/lrs3/metadata \
  --keep-stress

# Keep punctuation symbols in phonemes
python create_phoneme_metadata.py \
  --metadata-dir /path/to/lrs3/metadata \
  --keep-punctuation

# Full control over phoneme format
python create_phoneme_metadata.py \
  --metadata-dir /path/to/lrs3/metadata \
  --splits train,valid,test \
  --keep-stress \
  --keep-punctuation
```

## Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--metadata-dir` | Required | Directory containing `.wrd` files from step 3 |
| `--splits` | `train,valid,test` | Comma-separated list of splits to process |
| `--keep-stress` | False | Keep stress markers (0,1,2) in phonemes |
| `--keep-punctuation` | False | Keep punctuation symbols in phoneme set |

## Output Files

The script generates the following files in your metadata directory:

### Phoneme Transcript Files
- **`train.phn`** - Training phoneme sequences
- **`valid.phn`** - Validation phoneme sequences  
- **`test.phn`** - Test phoneme sequences

Each line contains space-separated phonemes corresponding to the words in the original `.wrd` files.

### Phoneme Dictionary
- **`dict.phn.txt`** - Phoneme vocabulary with frequency counts

Format: `<phoneme> <count>`
```
<blank> 25847
AH 18234
T 15692
IH 12456
...
```

The `<blank>` token count is automatically calculated as 10% of total phonemes for CTC training.

## Example Conversion

### Input (words):
```
HELLO WORLD
TIME IS RUNNING OUT
```

### Output (phonemes):
```
HH AH L OW W ER L D
T AY M IH Z R AH N IH NG AW T
```

## Phoneme Set Information

### Default Phoneme Set (CMU Dictionary)
The script uses the CMU Pronouncing Dictionary phoneme set via g2p-en:

**Vowels:** AA, AE, AH, AO, AW, AY, EH, ER, EY, IH, IY, OW, OY, UH, UW  
**Consonants:** B, CH, D, DH, F, G, HH, JH, K, L, M, N, NG, P, R, S, SH, T, TH, V, W, Y, Z, ZH

### Stress Markers (removed by default)
- `0` - No stress
- `1` - Primary stress  
- `2` - Secondary stress

Example: `AH1` ‚Üí `AH` (stress marker removed)

### Punctuation (removed by default)
Punctuation symbols `'`, `,`, `.` are filtered out from the phoneme sequences.

## Integration with Training

### For AV-HuBERT Training
The generated files are compatible with AV-HuBERT phoneme-based training:

1. Use `dict.phn.txt` as your vocabulary file
2. Use `.phn` files as your transcript inputs
3. The `<blank>` token is properly formatted for CTC loss

### Directory Structure After Conversion
```
/path/to/lrs3/metadata/
‚îú‚îÄ‚îÄ train.tsv, valid.tsv, test.tsv    # Original word-level manifests
‚îú‚îÄ‚îÄ train.wrd, valid.wrd, test.wrd    # Original word transcripts
‚îú‚îÄ‚îÄ train.phn, valid.phn, test.phn    # NEW: Phoneme transcripts  
‚îú‚îÄ‚îÄ dict.wrd.txt                      # Original word dictionary
‚îú‚îÄ‚îÄ dict.phn.txt                      # NEW: Phoneme dictionary
‚îî‚îÄ‚îÄ spm1000/                          # SentencePiece vocabulary (words)
```

## Statistics and Validation

The script provides detailed statistics during conversion:

```
üìù Processing train split: /path/to/metadata/train.wrd
Converting train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1234/1234 [00:05<00:00, 245.67it/s]
  ‚úÖ Created /path/to/metadata/train.phn
     üìä 1,234 sequences, 45,678 phonemes

üìã Creating phoneme dictionary: /path/to/metadata/dict.phn.txt
  ‚úÖ Dictionary created with 42 unique phonemes
     üìä Total phoneme tokens: 123,456
     üìä Calculated <blank> count (10%): 12,346

üìà Top 10 most frequent phonemes:
   1. <blank>   : 12,346
   2. AH        : 8,234
   3. T         : 7,123
   4. IH        : 6,789
   ...
```

## Troubleshooting

### Common Issues

**1. Import Error: `g2p_en` not found**
```bash
pip install g2p-en
```

**2. Missing `.wrd` files**
```
‚ùå Error: Missing required .wrd files:
   /path/to/metadata/train.wrd
```
**Solution:** Run the LRS3 preprocessing pipeline (step3_metadata_prep.py) first.

**3. Empty phoneme output**
**Cause:** Empty or malformed input files  
**Solution:** Check that `.wrd` files contain valid text transcripts.

### Performance Notes
- Processing ~1000 sentences takes approximately 1-2 minutes
- Memory usage is minimal (< 1GB for large datasets)
- No GPU required for G2P conversion

## Advanced Usage

### Custom Phoneme Processing
You can modify the script to:
- Use different G2P models
- Apply custom phoneme mappings
- Add language-specific processing
- Implement custom stress/punctuation handling

### Integration with Other Datasets
The script can be adapted for other datasets by:
- Changing input file formats
- Modifying phoneme filtering rules
- Adjusting dictionary creation logic

## References

- [g2p-en](https://github.com/Kyubyong/g2p): English G2P conversion library
- [CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict): Phoneme definitions
- [AV-HuBERT](https://github.com/facebookresearch/av_hubert): Phoneme-based lip reading model

---

## Complete Example

```bash
# 1. Complete LRS3 preprocessing pipeline first
python preparation/step1_prepare_lrs3_all.py --data-dir /path/to/lrs3 --root-dir /path/to/output --subset train --dataset lrs3
python preparation/step2_generate_file_lists.py --lrs3-data-dir /path/to/output/lrs3_video_seg16s  
python preparation/step3_metadata_prep.py --lrs3-data-dir /path/to/output/lrs3_video_seg16s --metadata-dir /path/to/output/metadata

# 2. Convert to phonemes
python create_phoneme_metadata.py --metadata-dir /path/to/output/metadata

# 3. Ready for phoneme-based training!
```

Your LRS3 dataset is now ready for both word-level and phoneme-level lip reading training! üéâ
